{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gemammercado/IsraelPalestineResearch/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bfb63f2-c541-484a-8aa5-6896d5ad59d8",
      "metadata": {
        "id": "8bfb63f2-c541-484a-8aa5-6896d5ad59d8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import zipfile\n",
        "import nltk\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from google.colab import drive\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "os.environ['SHELL'] = '/opt/homebrew/bin/bash'\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/bert_predictions.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "\"\"\"!pip uninstall nltk -y # Uninstall NLTK\n",
        "!pip install --upgrade --force-reinstall nltk # Reinstall NLTK\n",
        "\n",
        "import nltk\n",
        "nltk.download('vader_lexicon') # Download vader_lexicon\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d97da46b-805a-4a12-94ee-d2f5e6eac8cc",
      "metadata": {
        "id": "d97da46b-805a-4a12-94ee-d2f5e6eac8cc"
      },
      "source": [
        "\n",
        "Now we have a filtered_df and csv of the final data we are going to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "624d96c6-4bc7-4198-92b3-3a9c8fb922fd",
      "metadata": {
        "id": "624d96c6-4bc7-4198-92b3-3a9c8fb922fd"
      },
      "outputs": [],
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "vader_sample_size = 10000\n",
        "bert_sample_size = 250000\n",
        "\n",
        "vader_df = df.sample(n=vader_sample_size, random_state=42)\n",
        "\n",
        "remaining_df = df.drop(vader_df.index)\n",
        "\n",
        "bert_df = remaining_df.sample(n=bert_sample_size, random_state=42)\n",
        "\n",
        "print(f\"VADER subset size: {len(vader_df)}\")\n",
        "print(f\"BERT subset size: {len(bert_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9309d42f-42e6-44fd-a978-1b3ca19ac777",
      "metadata": {
        "id": "9309d42f-42e6-44fd-a978-1b3ca19ac777"
      },
      "outputs": [],
      "source": [
        "def clean_text(self_text):\n",
        "    text = re.sub(r\"http\\S+\", \"\", self_text)\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)\n",
        "    text = re.sub(r\"[^A-Za-z0-9\\s]\", \"\", text)\n",
        "    text = self_text.lower().strip()\n",
        "    return text\n",
        "\n",
        "vader_df['clean_text'] = vader_df['self_text'].apply(lambda x: clean_text(str(x)))\n",
        "\n",
        "print(vader_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_df['clean_text'] = bert_df['self_text'].apply(lambda x: clean_text(str(x)))\n",
        "\n",
        "print(bert_df.head())"
      ],
      "metadata": {
        "id": "Hzva4f6EyrOJ"
      },
      "id": "Hzva4f6EyrOJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a1d416b-9663-4e7c-832f-1882a869413f",
      "metadata": {
        "id": "2a1d416b-9663-4e7c-832f-1882a869413f"
      },
      "outputs": [],
      "source": [
        "vader_df['vader_sentiment'] = vader_df['clean_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
        "\n",
        "vader_df['sentiment_label'] = vader_df['vader_sentiment'].apply(lambda score: 'extreme negative' if score <-0.5 else\n",
        "                                                                  'negative' if -0.5<= score < -.05 else\n",
        "                                                                  'positive' if score >=0.05 else\n",
        "                                                                  'neutral')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d5b0b9a-f5c1-436d-8ef9-a53bede023d3",
      "metadata": {
        "id": "3d5b0b9a-f5c1-436d-8ef9-a53bede023d3"
      },
      "outputs": [],
      "source": [
        "print(vader_df[['clean_text', 'vader_sentiment', 'sentiment_label']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bcf7b77-6b14-45ef-8545-13d6619d8b43",
      "metadata": {
        "id": "3bcf7b77-6b14-45ef-8545-13d6619d8b43"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(vader_df, test_size=0.2, random_state=42)\n",
        "\n",
        "label_map = {'extreme negative': 0, 'negative':1, 'neutral': 2, 'positive':3}\n",
        "train_labels = train_df['sentiment_label'].map(label_map).tolist()\n",
        "test_labels = test_df['sentiment_label'].map(label_map).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1981d5da-c0ef-4172-8a2e-3147832adec8",
      "metadata": {
        "id": "1981d5da-c0ef-4172-8a2e-3147832adec8"
      },
      "outputs": [],
      "source": [
        "print(train_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "439d5cf3-14e1-47ee-9149-a3dcb7d41548",
      "metadata": {
        "id": "439d5cf3-14e1-47ee-9149-a3dcb7d41548"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize_data(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "train_encodings = tokenize_data(train_df['clean_text'].tolist())\n",
        "test_encodings = tokenize_data(test_df['clean_text'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19bf6712-3aa8-446b-b8c6-fb8d1b664405",
      "metadata": {
        "id": "19bf6712-3aa8-446b-b8c6-fb8d1b664405"
      },
      "outputs": [],
      "source": [
        "class SentimentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed915471-1b5a-468c-b540-3ae3f7d2f11b",
      "metadata": {
        "id": "ed915471-1b5a-468c-b540-3ae3f7d2f11b"
      },
      "outputs": [],
      "source": [
        "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
        "test_dataset = SentimentDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09a08eb3-e378-408d-8558-1036bbf2c4c5",
      "metadata": {
        "id": "09a08eb3-e378-408d-8558-1036bbf2c4c5"
      },
      "source": [
        "Define and train BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec73021-4b1f-44ae-9f28-e973f3dda822",
      "metadata": {
        "id": "eec73021-4b1f-44ae-9f28-e973f3dda822"
      },
      "outputs": [],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = len(label_map))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = './results',\n",
        "    save_steps = 500,\n",
        "    save_total_limit = 2,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate = 2e-5,\n",
        "    per_device_train_batch_size = 8,\n",
        "    per_device_eval_batch_size = 8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay = 0.01\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = test_dataset\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4_Uwq7sL55RG",
      "metadata": {
        "id": "4_Uwq7sL55RG"
      },
      "outputs": [],
      "source": [
        "# Save model and training state after each epoch\n",
        "trainer.save_model('/content/drive/MyDrive/bert_training/bert_classifier')\n",
        "trainer.save_state()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.save(train_encodings, '/content/drive/MyDrive/train_encodings.pt')\n",
        "torch.save(test_encodings, '/content/drive/MyDrive/test_encodings.pt')\n",
        "torch.save(train_labels, '/content/drive/MyDrive/train_labels.pt')\n",
        "torch.save(test_labels, '/content/drive/MyDrive/test_labels.pt')\n"
      ],
      "metadata": {
        "id": "0PEFBFW6zw_E"
      },
      "id": "0PEFBFW6zw_E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i4HnE_Kn6A_D",
      "metadata": {
        "id": "i4HnE_Kn6A_D"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(resume_from_checkpoint='/content/drive/MyDrive/bert_training/bert_classifier/checkpoint-2000')"
      ],
      "metadata": {
        "id": "0YLx6UMTPWhV"
      },
      "id": "0YLx6UMTPWhV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load model\n",
        "model_path = '/content/drive/MyDrive/bert_training/bert_classifier'\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "XqYYcmUbxE6Z"
      },
      "id": "XqYYcmUbxE6Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_encodings = tokenize_data(bert_df['clean_text'].tolist())\n",
        "remaining_dataset = SentimentDataset(remaining_encodings)"
      ],
      "metadata": {
        "id": "HV_qXmoB7XX3"
      },
      "id": "HV_qXmoB7XX3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    per_device_eval_batch_size=128,\n",
        "    output_dir=\"./results\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "predictions = trainer.predict(remaining_dataset)\n",
        "\n",
        "predicted_labels = predictions.predictions.argmax(axis=1)\n",
        "\n",
        "print(\"Predictions complete!\")\n"
      ],
      "metadata": {
        "id": "m-Lxnfa4qdLu"
      },
      "id": "m-Lxnfa4qdLu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_label_map = {v: k for k, v in label_map.items()}\n",
        "\n",
        "predicted_indices = predicted_labels\n",
        "\n",
        "predicted_labels = [reverse_label_map[idx] for idx in predicted_indices]\n",
        "\n",
        "bert_df['predicted_label'] = predicted_labels\n",
        "\n",
        "# Save to CSV\n",
        "output_csv_path = '/content/drive/MyDrive/bert_predictions.csv'\n",
        "bert_df.to_csv(output_csv_path, index=False)\n",
        "print(f\"Predictions saved to: {output_csv_path}\")"
      ],
      "metadata": {
        "id": "mU4LcqWvwbue"
      },
      "id": "mU4LcqWvwbue",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kLJyl20E6q-S",
      "metadata": {
        "id": "kLJyl20E6q-S"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#analysis\n",
        "\n",
        "print(df['predicted_label'].value_counts())\n",
        "\n",
        "#visualize\n",
        "df['predicted_label'].value_counts().plot(kind='bar')\n",
        "plt.xlabel('Sentiment Distribution')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('BERT Sentiment Analysis')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map sentiment labels to numeric values\n",
        "label_map = {0: 'extreme negative', 1: 'negative', 2: 'neutral', 3:'positive'}\n",
        "df['predicted_label'] = df['predicted_label'].map(label_map)\n"
      ],
      "metadata": {
        "id": "2-R_aFTvR1dS"
      },
      "id": "2-R_aFTvR1dS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "HqlCmUhfXnxw"
      },
      "id": "HqlCmUhfXnxw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.ticker as mticker\n",
        "\n",
        "#group by subreddit and calculate proportion of extreme sentiment\n",
        "subreddit_extremism = df.groupby('subreddit')['predicted_label'].value_counts(normalize=True).unstack().fillna(0)\n",
        "\n",
        "subreddit_extremism = subreddit_extremism.reset_index()\n",
        "plt.figure(figsize=(10, 6))\n",
        "subreddit_extremism_melted = subreddit_extremism.melt(id_vars='subreddit', var_name='Sentiment', value_name='Proportion')\n",
        "custom_colors = ['#A92222', '#EC1414', '#B2B2B2', '#0000']  # Replace with your desired colors\n",
        "\n",
        "sns.barplot(\n",
        "    data=subreddit_extremism_melted,\n",
        "    x='subreddit',\n",
        "    y='Proportion',\n",
        "    hue='Sentiment',\n",
        "    palette=custom_colors\n",
        ")\n",
        "\n",
        "plt.gca().yaxis.set_major_formatter(mticker.FuncFormatter(lambda y, _: f'{y * 100:.0f}%'))\n",
        "\n",
        "plt.title('Proportion of Sentiments by Subreddit')\n",
        "plt.xlabel('Subreddit')\n",
        "plt.ylabel('Proportion')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Sentiment')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8haoqCUaUDPC"
      },
      "id": "8haoqCUaUDPC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "palette = sns.color_palette(\"Set2\", n_colors=df['predicted_label'].nunique())\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=df, x='subreddit', y='score', hue='predicted_label', palette=palette)\n",
        "\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.title('Sentiment Score Distribution by Subreddit', fontsize=16)\n",
        "plt.xlabel('Subreddit', fontsize=12)\n",
        "plt.ylabel('Score (Log Scale)', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Sentiment', loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "auOWDr8nW1dU"
      },
      "id": "auOWDr8nW1dU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df['created_time'] = pd.to_datetime(df['created_time'])\n",
        "df['month'] = df['created_time'].dt.to_period('M').astype(str)\n",
        "\n",
        "sentiment_counts = df.groupby(['month', 'subreddit', 'predicted_label']).size().unstack(fill_value=0)\n",
        "\n",
        "sentiment_proportions = sentiment_counts.div(sentiment_counts.sum(axis=1), axis=0)\n",
        "\n",
        "sentiment_proportions = sentiment_proportions.reset_index()\n",
        "\n",
        "df_melted = sentiment_proportions.melt(id_vars=['month', 'subreddit'],\n",
        "                                       value_vars=['extreme negative', 'negative', 'neutral', 'positive'],\n",
        "                                       var_name='Sentiment',\n",
        "                                       value_name='Proportion')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "custom_colors = {\n",
        "    'extreme negative': '#A92222',\n",
        "    'negative': '#EC1414',\n",
        "    'neutral': '#B2B2B2',\n",
        "    'positive': '#020405'\n",
        "}\n",
        "\n",
        "for sentiment, color in custom_colors.items():\n",
        "    linewidth = 2.5 if sentiment in ['extreme negative', 'negative'] else 1.5\n",
        "    sns.lineplot(\n",
        "        data=df_melted[df_melted['Sentiment'] == sentiment],\n",
        "        x='month',\n",
        "        y='Proportion',\n",
        "        label=sentiment,\n",
        "        color=color,\n",
        "        linewidth=linewidth,\n",
        "        marker='o',\n",
        "        ci=None\n",
        "    )\n",
        "\n",
        "plt.gca().yaxis.set_major_formatter(mticker.FuncFormatter(lambda y, _: f'{y * 100:.0f}%'))\n",
        "\n",
        "plt.title('Sentiment Over Time', fontsize=16)\n",
        "plt.xlabel('Month', fontsize=12)\n",
        "plt.ylabel('Proportion of Sentiment', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Sentiment', loc='upper left')\n",
        "plt.ylim(0, 0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1emELruNhZZQ"
      },
      "id": "1emELruNhZZQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['created_time'] = pd.to_datetime(df['created_time'])\n",
        "df['month'] = df['created_time'].dt.to_period('M').astype(str)\n",
        "sentiment_counts = df.groupby(['month', 'predicted_label']).size().unstack(fill_value=0)\n",
        "\n",
        "positive_count = sentiment_counts.get('positive', 0)\n",
        "negative_count = sentiment_counts.get('negative', 0) + sentiment_counts.get('extreme negative', 0)\n",
        "\n",
        "polarity = positive_count / negative_count\n",
        "polarity[negative_count == 0] = float('inf')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(polarity.index, polarity.values, marker='o', linestyle='-', color='b', label='Polarity')\n",
        "plt.title('Polarity Over Time (Month to Month)', fontsize=16)\n",
        "plt.xlabel('Month', fontsize=12)\n",
        "plt.ylabel('Polarity (Positive/Negative Ratio)', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.ylim(0.0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nQjeCuMRkiDV"
      },
      "id": "nQjeCuMRkiDV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['created_time'] = pd.to_datetime(df['created_time'])\n",
        "df['month'] = df['created_time'].dt.to_period('M').astype(str)\n",
        "\n",
        "df_controversial = df[df['controversiality'] == 1]\n",
        "\n",
        "df_non_controversial = df[df['controversiality'] == 0]\n",
        "\n",
        "sentiment_controversial = df_controversial.groupby(['month', 'predicted_label']).size().unstack(fill_value=0)\n",
        "sentiment_non_controversial = df_non_controversial.groupby(['month', 'predicted_label']).size().unstack(fill_value=0)\n",
        "\n",
        "positive_controversial = sentiment_controversial.get('positive', 0)\n",
        "negative_controversial = sentiment_controversial.get('negative', 0) + sentiment_controversial.get('extreme negative', 0)\n",
        "polarity_controversial = positive_controversial / negative_controversial\n",
        "polarity_controversial[negative_controversial == 0] = float('inf')\n",
        "\n",
        "positive_non_controversial = sentiment_non_controversial.get('positive', 0)\n",
        "negative_non_controversial = sentiment_non_controversial.get('negative', 0) + sentiment_non_controversial.get('extreme negative', 0)\n",
        "polarity_non_controversial = positive_non_controversial / negative_non_controversial\n",
        "polarity_non_controversial[negative_non_controversial == 0] = float('inf')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.plot(polarity_controversial.index, polarity_controversial.values, marker='o', linestyle='-', color='red', label='Controversial (1)')\n",
        "\n",
        "plt.plot(polarity_non_controversial.index, polarity_non_controversial.values, marker='o', linestyle='-', color='blue', label='Non-Controversial (0)')\n",
        "\n",
        "plt.title('Polarity Over Time: Controversial vs Non-Controversial Posts', fontsize=16)\n",
        "plt.xlabel('Month', fontsize=12)\n",
        "plt.ylabel('Polarity (Positive/Negative Ratio)', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.ylim(0.0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0lH5VJgKODOm"
      },
      "id": "0lH5VJgKODOm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "extreme_negative_data = df[df['predicted_label'] == 'extreme negative']\n",
        "\n",
        "total_sentiments = df.groupby(['month', 'subreddit']).size()\n",
        "\n",
        "extreme_negative_counts = extreme_negative_data.groupby(['month', 'subreddit']).size()\n",
        "\n",
        "extreme_negative_proportions = (extreme_negative_counts / total_sentiments).fillna(0) * 100\n",
        "\n",
        "extreme_negative_proportions = extreme_negative_proportions.reset_index()\n",
        "extreme_negative_proportions.columns = ['Month', 'Subreddit', 'Proportion']\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(\n",
        "    data=extreme_negative_proportions,\n",
        "    x='Month',\n",
        "    y='Proportion',\n",
        "    hue='Subreddit',\n",
        "    marker='o'\n",
        ")\n",
        "\n",
        "plt.gca().yaxis.set_major_formatter(mticker.FuncFormatter(lambda y, _: f'{y}%'))\n",
        "\n",
        "plt.title('Percentage of Extreme Negative Sentiment Over Time by Subreddit', fontsize=16)\n",
        "plt.xlabel('Month', fontsize=12)\n",
        "plt.ylabel('Percentage of Extreme Negative Sentiment', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Subreddit', loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sZ_BkWeNQRvw"
      },
      "id": "sZ_BkWeNQRvw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For my hypothesis:"
      ],
      "metadata": {
        "id": "20xnOuv3jlh0"
      },
      "id": "20xnOuv3jlh0"
    },
    {
      "cell_type": "code",
      "source": [
        "df['extreme_negative'] = df['predicted_label'] == 'extreme negative'\n",
        "\n",
        "polarization_by_subreddit = df.groupby(['month', 'subreddit'])['extreme_negative'].mean().reset_index()\n",
        "\n",
        "print(polarization_by_subreddit.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "F_LDDU9PW37L"
      },
      "id": "F_LDDU9PW37L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "subreddit_groups = [group['extreme_negative'].values for name, group in polarization_by_subreddit.groupby('subreddit')]\n",
        "anova_result = f_oneway(*subreddit_groups)\n",
        "\n",
        "print(f'ANOVA F-statistic: {anova_result.statistic}, p-value: {anova_result.pvalue}')\n"
      ],
      "metadata": {
        "id": "7zsMbzrCjtoS"
      },
      "id": "7zsMbzrCjtoS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "df['month_numeric'] = pd.to_datetime(df['month']).astype(int) / 10**9\n",
        "\n",
        "X = sm.add_constant(df['month_numeric'])\n",
        "y = df['extreme_negative']\n",
        "\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "krcKxr3sj6oh"
      },
      "id": "krcKxr3sj6oh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['extreme_negative_numeric'] = df['extreme_negative'].astype(int)\n",
        "\n",
        "model = ols('extreme_negative_numeric ~ C(subreddit)', data=df).fit()\n",
        "\n",
        "anova_result = sm.stats.anova_lm(model, typ=2)\n",
        "print(anova_result)\n",
        "\n",
        "tukey_result = pairwise_tukeyhsd(df['extreme_negative_numeric'], df['subreddit'], alpha=0.05)\n",
        "print(tukey_result)\n",
        "\n"
      ],
      "metadata": {
        "id": "Hv76sehckj2P"
      },
      "id": "Hv76sehckj2P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "id": "_w6tSTCFXnzD"
      },
      "id": "_w6tSTCFXnzD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "oct24 = sentiment_proportions[sentiment_proportions['month'] == '2024-09']['extreme negative'] + sentiment_proportions[sentiment_proportions['month'] == '2024-09']['negative']\n",
        "oct23 = sentiment_proportions[sentiment_proportions['month'] == '2023-11']['extreme negative'] + sentiment_proportions[sentiment_proportions['month'] == '2023-11']['negative']\n",
        "\n",
        "\n",
        "t_stat, p_value = stats.ttest_ind(oct24, oct23, equal_var=False)\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n"
      ],
      "metadata": {
        "id": "z0Dfx3EtQfN6"
      },
      "id": "z0Dfx3EtQfN6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "before_oct24 = sentiment_proportions[sentiment_proportions['month'] == '2024-09']['positive']\n",
        "after_oct23 = sentiment_proportions[sentiment_proportions['month'] =='2023-11']['positive']\n",
        "\n",
        "t_stat, p_value = stats.ttest_ind(before_oct24, after_oct23)\n",
        "\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "c0dhMc6OULij"
      },
      "id": "c0dhMc6OULij",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_filtered = df[df['controversiality'] == 1].copy()\n",
        "\n",
        "df_filtered['created_time'] = pd.to_datetime(df_filtered['created_time'])\n",
        "\n",
        "df_filtered['month'] = df_filtered['created_time'].dt.to_period('M').astype(str)\n",
        "\n",
        "monthly_controversial_count = df_filtered.groupby('month').size()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "monthly_controversial_count.plot(kind='line', marker='o', color='red')\n",
        "plt.title('Count of Controversial Posts by Month', fontsize=16)\n",
        "plt.xlabel('Month', fontsize=12)\n",
        "plt.ylabel('Count of Controversial Posts', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ROWellvrmDks"
      },
      "id": "ROWellvrmDks",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "df['created_time'] = pd.to_datetime(df['created_time'])\n",
        "\n",
        "before_oct = df[df['created_time'] < '2023-12-01']\n",
        "after_oct = df[df['created_time'] >= '2024-12-01']\n",
        "\n",
        "t_stat, p_value = stats.ttest_ind(before_oct['controversiality'], after_oct['controversiality'], equal_var=False)\n",
        "\n",
        "print(before_oct)\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n"
      ],
      "metadata": {
        "id": "SrdBJEj1_FAq"
      },
      "id": "SrdBJEj1_FAq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}